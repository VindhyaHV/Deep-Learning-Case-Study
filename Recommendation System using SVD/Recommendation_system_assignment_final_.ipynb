{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommendation_system_assignment_final_.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeM0ZBWUVtXR"
      },
      "source": [
        "# <font color='red'>SGD Algorithm to predict movie ratings</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2vyJqSlmmjM"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_matrix(), grader_mean(), grader_dim() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL6njTf8WBO0"
      },
      "source": [
        "<pre>\n",
        "1. Download the data from <a href='https://drive.google.com/open?id=1-1z7iDB52cB6_JpO7Dqa-eOYSs-mivpq'> here </a>\n",
        "2. The data will be of this format, each data point is represented as a triplet of user_id, movie_id and rating \n",
        "<table>\n",
        "<tr><th>user_id</th><th>movie_id</th><th>rating</th></tr>\n",
        "<tr><td>77</td><td>236</td><td>3</td></tr>\n",
        "<tr><td>471</td><td>208</td><td>5</td></tr>\n",
        "<tr><td>641</td><td>401</td><td>4</td></tr>\n",
        "<tr><td>31</td><td>298</td><td>4</td></tr>\n",
        "<tr><td>58</td><td>504</td><td>5</td></tr>\n",
        "<tr><td>235</td><td>727</td><td>5</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73dhFsT0WSSB"
      },
      "source": [
        "## <font color='red'>Task 1</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY0frS6EWaEV"
      },
      "source": [
        "<font color='red'><b>Predict the rating for a given (user_id, movie_id) pair </b> </font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-ISYxaVbT8L"
      },
      "source": [
        "Predicted rating $\\hat{y}_{ij}$ for user i, movied j pair is calcuated as $\\hat{y}_{ij} = \\mu + b_i + c_j + u_i^T v_j$ , here we will be finding the best values of $b_{i}$ and $c_{j}$ using SGD algorithm with the optimization problem for N users and M movies is defined as"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Aj8SXeQWlZd"
      },
      "source": [
        "$$\n",
        "L = \\min_{ b, c, \\{ u_i \\}_{i=1}^N, \\{ v_j \\}_{j=1}^M}\n",
        "\\quad\n",
        "\\alpha \\Big(\n",
        "    \\sum_{j} \\sum_{k} v_{jk}^2 \n",
        "    + \\sum_{i} \\sum_{k} u_{ik}^2 \n",
        "    + \\sum_{i} b_i^2\n",
        "    + \\sum_{j} c_i^2\n",
        "    \\Big)\n",
        "+ \\sum_{i,j \\in \\mathcal{I}^{\\text{train}}}\n",
        "    (y_{ij} - \\mu - b_i - c_j - u_i^T v_j)^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q5bnWyZXrM7"
      },
      "source": [
        "<ul>\n",
        "<li><span class=\"math\">\\(\\mu\\)</span> : scalar mean rating</li>\n",
        "<li><span class=\"math\">\\(b_i\\)</span> : scalar bias term for user <span class=\"math\">\\(i\\)</span></li>\n",
        "<li><span class=\"math\">\\(c_j\\)</span> : scalar bias term for movie <span class=\"math\">\\(j\\)</span></li>\n",
        "<li><span class=\"math\">\\(u_i\\)</span> : K-dimensional vector for user <span class=\"math\">\\(i\\)</span></li>\n",
        "<li><span class=\"math\">\\(v_j\\)</span> : K-dimensional vector for movie <span class=\"math\">\\(j\\)</span></li>\n",
        "</ul>\n",
        "\n",
        " $ \\ $\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1cf4CunbEr4"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "*.  We will be giving you some functions, please write code in that functions only.\n",
        "\n",
        "*.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWQyB5hfy3u7"
      },
      "source": [
        "1. Construct adjacency matrix with the given data, assuming its graph and the weight of each edge is the rating given by user to the movie\n",
        "\n",
        "<img src='https://i.imgur.com/rmUCGMb.jpg' width=200>\n",
        "\n",
        "   you can construct this matrix like $A[i][j]=r_{ij}$ here $i$ is user_id, $j$ is movie_id and $r_{ij}$ is rating given by user $i$ to the movie $j$\n",
        "\n",
        "   Hint : you can create adjacency matrix using <a href='https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html'> csr_matrix</a>\n",
        "\n",
        "2. We will Apply SVD decomposition on the Adjaceny matrix <a href='https://stackoverflow.com/a/31528944/4084039'>link1</a>, <a href='https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/'> link2</a> and get three matrices $U, \\sum, V$ such that $U \\times \\sum \\times V^T = A$, <br> \n",
        "if $A$ is of dimensions $N \\times M$ then <br>\n",
        "U is of $N \\times k$, <br>\n",
        "$\\sum$ is of $k \\times k$ and <br>\n",
        "$V$ is $M \\times k$ dimensions. <br>\n",
        "\n",
        "   *.  So the matrix $U$ can be represented as matrix representation of users, where each row $u_{i}$ represents a k-dimensional vector for a user\n",
        "\n",
        "   *. So the matrix $V$ can be represented as matrix representation of movies, where each row $v_{j}$ represents a k-dimensional vector for a movie.\n",
        "3. Compute $\\mu$ , $\\mu$  represents the mean of all the rating given in the dataset.(write your code in <font color='blue'>def m_u()</font>)\n",
        "4. For each unique user initilize a bias value $B_{i}$ to zero, so if we have $N$ users $B$ will be a $N$ dimensional vector, the $i^{th}$ value of the $B$ will corresponds to the bias term for $i^{th}$ user (write your code in <font color='blue'>def initialize()</font>)\n",
        "\n",
        "5. For each unique movie initilize a bias value $C_{j}$ zero, so if we have $M$ movies $C$ will be a $M$ dimensional vector, the $j^{th}$ value of the $C$ will corresponds to the bias term for $j^{th}$ movie (write your code in <font color='blue'>def initialize()</font>)\n",
        "\n",
        "6. Compute dL/db_i (Write you code in <font color='blue'> def derivative_db()</font>)\n",
        "7. Compute dL/dc_j(write your code in <font color='blue'> def derivative_dc()</font>\n",
        "\n",
        "8. Print the mean squared error with predicted ratings.\n",
        "\n",
        "<pre>\n",
        "for each epoch:\n",
        "    for each pair of (user, movie):\n",
        "        b_i =  b_i - learning_rate * dL/db_i\n",
        "        c_j =  c_j - learning_rate * dL/dc_j\n",
        "predict the ratings with formula\n",
        "</pre>\n",
        "$\\hat{y}_{ij} = \\mu + b_i + c_j + \\text{dot_product}(u_i , v_j) $\n",
        "\n",
        "9. you can choose any learning rate and regularization term in the range $10^{-3}  \\text{ to } 10^2$  <br>\n",
        "  \n",
        "10. __bonus__: instead of using SVD decomposition you can learn the vectors $u_i$, $v_j$ with the help of SGD algo similar to $b_i$ and $c_j$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlPVJoZ8JN4P"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2XrlYeuJOFq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-aBnRepA6gy"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP_6xMAZA4mE"
      },
      "source": [
        " # <font color='red'>Task 2 </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9HCN_3WA2au"
      },
      "source": [
        "As we know U is the learned matrix of user vectors, with its i-th row as the vector ui for user i. Each row of U can be seen as a \"feature vector\" for a particular user.\n",
        "\n",
        "The question we'd like to investigate is this: do our computed per-user features that are optimized for predicting movie ratings contain anything to do with gender?\n",
        "\n",
        "The provided data file <a href='https://drive.google.com/open?id=1PHFdJh_4gIPiLH5Q4UErH8GK71hTrzlY'>user_info.csv</a> contains an is_male column indicating which users in the dataset are male. Can you predict this signal given the features U?\n",
        "\n",
        "\n",
        "> __Note 1__ : there is no train test split in the data, the goal of this assignment is to give an intution about how to do matrix factorization with the help of SGD and application of truncated SVD. for better understanding of the collabarative fillerting please check netflix case study. <br><br>\n",
        "> __Note 2__ : Check if scaling of $U$, $V$ matrices improve the metric "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovFCo1JCBIXM"
      },
      "source": [
        "<br>\n",
        "\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVJo-3njBQLf"
      },
      "source": [
        "<font color='red'> Reading the csv file </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bA7IqlGO2R2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn import tree\n",
        "from google.colab import files\n",
        "import io\n",
        "import pandas as pd"
      ],
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "7Fhugc_OPzuJ",
        "outputId": "ee42ba21-eb6f-4c97-a833-163f98a186b3"
      },
      "source": [
        "\n",
        "uploaded = files.upload ()"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-26828dcf-9fdc-4f7d-bf6c-09a516016184\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-26828dcf-9fdc-4f7d-bf6c-09a516016184\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ratings_train.csv to ratings_train (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hEhmfRD637EW",
        "outputId": "4de55779-be0f-4d1d-bd3c-7b524b32342d"
      },
      "source": [
        "\n",
        "data=pd.read_csv(io.BytesIO(uploaded['ratings_train.csv']))\n",
        "data.head()"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>772</td>\n",
              "      <td>36</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>471</td>\n",
              "      <td>228</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>641</td>\n",
              "      <td>401</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>312</td>\n",
              "      <td>98</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>58</td>\n",
              "      <td>504</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  item_id  rating\n",
              "0      772       36       3\n",
              "1      471      228       5\n",
              "2      641      401       4\n",
              "3      312       98       4\n",
              "4       58      504       5"
            ]
          },
          "metadata": {},
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66ibGJ74hCde",
        "outputId": "6d0537c0-9b5f-46f1-e3e5-96e4cd04f631"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(89992, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvB8SDS_hW03"
      },
      "source": [
        "<font color='red'>Create your adjacency matrix </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SrNTvjeTH0D",
        "outputId": "c8d33e19-1efc-4de3-8c30-aaab640009c3"
      },
      "source": [
        "users =data['user_id'].unique()\n",
        "len(users)\n",
        "items = data['item_id'].unique()\n",
        "len(items)\n",
        "ratings = data['rating']\n",
        "ratings.shape"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(89992,)"
            ]
          },
          "metadata": {},
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t44MNT40hZQW"
      },
      "source": [
        "#csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
        "from scipy.sparse import csr_matrix\n",
        "adjacency_matrix = csr_matrix((data['rating'],(data['user_id'],data['item_id'])))# write your code of adjacency matrix here"
      ],
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mCgC0WbhZTO",
        "outputId": "812ce718-58ae-4428-b578-bf597359295e"
      },
      "source": [
        "adjacency_matrix.shape"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(943, 1681)"
            ]
          },
          "metadata": {},
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgm1DhSE9r-P"
      },
      "source": [
        "adj = adjacency_matrix.toarray()"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WRkgBkAIhKc",
        "outputId": "7a27c7b3-f01f-415a-8b41-ac12a4fa1930"
      },
      "source": [
        "adj[0][0]"
      ],
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4acJD4ujEtD6"
      },
      "source": [
        "<font color='cyan'>Grader function - 1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QuTzFBREsDV",
        "outputId": "43c7b789-8271-4228-98f5-532b6bf6dc7e"
      },
      "source": [
        "def grader_matrix(matrix):\n",
        "  assert(matrix.shape==(943,1681))\n",
        "  return True\n",
        "grader_matrix(adjacency_matrix)"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7VwkRNeHpWE"
      },
      "source": [
        "**The unique items in the given csv file are 1662 only . But the id's vary from 0-1681 but they are not continuous and hence \n",
        "you'll get matrix of size 943x1681.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXDf1RCUBsYN"
      },
      "source": [
        "<font color='red'> SVD decompostion</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJPWI9VwD_ih"
      },
      "source": [
        "Sample code for SVD decompostion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GATD35bmBszc",
        "outputId": "a6bb899d-ab0f-4b36-f867-173ce9e6eff2"
      },
      "source": [
        "from sklearn.utils.extmath import randomized_svd\n",
        "import numpy as np \n",
        "matrix = np.random.random((20, 10))\n",
        "U, Sigma, VT = randomized_svd(matrix, n_components=5,n_iter=5, random_state=None)\n",
        "print(U.shape)\n",
        "print(Sigma.shape)\n",
        "print(VT.T.shape)"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 5)\n",
            "(5,)\n",
            "(10, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePDgwALQEJoB"
      },
      "source": [
        "<font color='red'>Write your code for SVD decompostion</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYnsKBmFEIg3",
        "outputId": "710e14e9-b44e-4f28-d445-2805d91fef82"
      },
      "source": [
        "# Please use adjacency_matrix as matrix for SVD decompostion\n",
        "# You can choose n_components as your choice\n",
        "\n",
        "from sklearn.utils.extmath import randomized_svd\n",
        "import numpy as np \n",
        "U, Sigma, VT = randomized_svd(adjacency_matrix, n_components=50,n_iter=5, random_state=None)\n",
        "print(U.shape)\n",
        "print(Sigma.shape)\n",
        "print(VT.T.shape)"
      ],
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(943, 50)\n",
            "(50,)\n",
            "(1681, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Vh4NoO_JyU"
      },
      "source": [
        "<font color='red'>Compute mean of ratings</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBHuCn2QSEnl"
      },
      "source": [
        "def m_u(ratings):\n",
        "    '''In this function, we will compute mean for all the ratings'''\n",
        "    # you can use mean() function to do this\n",
        "    # check this (https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html) link for more details.\n",
        "    Mean = np.round(np.mean(ratings),3)\n",
        "    \n",
        "\n",
        "    return Mean"
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu1nn-1x3ebp",
        "outputId": "c40f16bd-db60-44ed-a074-d9584e59e3e6"
      },
      "source": [
        "mu=m_u(data['rating'])\n",
        "print(mu)"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76ooYQIdG_tf"
      },
      "source": [
        "<font color='cyan'>Grader function -2 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZy1m67oG9r9",
        "outputId": "a482fd9f-1119-44ab-c7ab-f65be48b8c40"
      },
      "source": [
        "def grader_mean(mu):\n",
        "  assert(np.round(mu,3)==3.529)\n",
        "  return True\n",
        "mu=m_u(data['rating'])\n",
        "grader_mean(mu)"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSvAW1X94g3G"
      },
      "source": [
        "<font color='red'>Initialize $B_{i}$ and $C_{j}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsOl-4xq5aUG"
      },
      "source": [
        "Hint : Number of rows of adjacent matrix corresponds to user dimensions($B_{i}$), number of columns of adjacent matrix corresponds to movie dimensions ($C_{j}$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyEJqPka4lBW"
      },
      "source": [
        "def initialize(dim):\n",
        "    '''In this function, we will initialize bias value 'B' and 'C'.'''\n",
        "    # initalize the value to zeros \n",
        "    # return output as a list of zeros \n",
        "    Bi = np.zeros(dim)\n",
        "    return Bi"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nlae9QAQ43Xz",
        "outputId": "3cea0655-9e4f-4462-8ea4-1f4411758657"
      },
      "source": [
        "dim=adjacency_matrix.shape[0]# give the number of dimensions for b_i (Here b_i corresponds to users)\n",
        "b_i=initialize(dim)\n",
        "b_i.sum()"
      ],
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwuopn4HoEbP",
        "outputId": "9d6691e5-60f0-4269-d8b8-eef921f916e4"
      },
      "source": [
        "dim= adjacency_matrix.shape[1]# give the number of dimensions for c_j (Here c_j corresponds to movies)\n",
        "c_j=initialize(dim)\n",
        "c_j.sum()"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfPJ3_h6JIkI"
      },
      "source": [
        "<font color='cyan'>Grader function -3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQhiNjw0Hz4m",
        "outputId": "9333b817-ad5c-4e7f-d36b-db4d19936a6b"
      },
      "source": [
        "def grader_dim(b_i,c_j):\n",
        "  assert(len(b_i)==943 and np.sum(b_i)==0)\n",
        "  assert(len(c_j)==1681 and np.sum(c_j)==0)\n",
        "  return True\n",
        "grader_dim(b_i,c_j)"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTDK4ZR18MrZ"
      },
      "source": [
        "<font color='red'>Compute dL/db_i</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubSqi5VCf9q6",
        "outputId": "5eae4fde-506b-4259-8dd6-b59df373cc3d"
      },
      "source": [
        "data['rating'].shape"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(89992,)"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NFzVC1N8S4L"
      },
      "source": [
        "def derivative_db(user_id,item_id,rating,U,V,mu,alpha,b,c):\n",
        "    '''In this function, we will compute dL/db_i'''\n",
        "    alpha = 0.01\n",
        "    p1 = 2*b-2*(rating-mu-b-c-np.dot(U[user_id],V[:,item_id]))\n",
        "    #print(mu+np.sum(np.dot(U,V)))\n",
        "\n",
        "    return p1\n"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilISrTeQ0f0v"
      },
      "source": [
        "<font color='cyan'>Grader function -4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJW3DmTJqIwc"
      },
      "source": [
        "def grader_db(value):\n",
        "    assert(np.round(value,3)==-0.931)\n",
        "    return True"
      ],
      "execution_count": 300,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "Wt5ixEVZ043U",
        "outputId": "7321845d-a6d7-4d97-a416-9911281c24fb"
      },
      "source": [
        "U1, Sigma, V1 = randomized_svd(adjacency_matrix, n_components=2,n_iter=5, random_state=24)\n",
        "# Please don't change random state\n",
        "# Here we are considering n_componets = 2 for our convinence\n",
        "alpha=0.01 \n",
        "b = 0\n",
        "c = 0\n",
        "value=derivative_db(312,98,4,U1,V1,mu,alpha,b,c)\n",
        "print(np.round(value,3))\n",
        "grader_db(value)"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.932\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-301-227f898d2330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mderivative_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m312\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m98\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mU1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgrader_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-300-4216b7779205>\u001b[0m in \u001b[0;36mgrader_db\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrader_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.931\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Kp0hC_b9v60"
      },
      "source": [
        "<font color='red'>Compute dL/dc_j</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAtSYMrc9UqJ"
      },
      "source": [
        "def derivative_dc(user_id,item_id,rating,U,V,mu,alpha,b,c):\n",
        "    '''In this function, we will compute dL/dc_j'''\n",
        "    alpha = 0.01\n",
        "    p1 = 2*c-2*(rating-mu-b-c-np.dot(U[user_id],V[:,item_id]))\n",
        "\n",
        "\n",
        "    return p1"
      ],
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxkAm8aH1SBF"
      },
      "source": [
        "<font color='cyan'>Grader function - 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "RaIN9yie1US8",
        "outputId": "0e6bc827-1b8d-4fab-db1c-73f55b253b26"
      },
      "source": [
        "def grader_dc(value):\n",
        "    assert(np.round(value,3)==-2.929)\n",
        "    return True\n",
        "U1, Sigma, V1 = randomized_svd(adjacency_matrix, n_components=2,n_iter=5, random_state=24)\n",
        "# Please don't change random state\n",
        "# Here we are considering n_componets = 2 for our convinence\n",
        "r=0.01 \n",
        "value=derivative_dc(58,504,5,U1,V1,mu,alpha,b,c)\n",
        "print(round(value,3))\n",
        "grader_dc(value)\n",
        "#print(value)\n",
        "\n",
        "U1.shape"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-2.93\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-303-3e58a37f03fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mderivative_dc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m58\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m504\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mU1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgrader_dc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#print(value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-303-3e58a37f03fc>\u001b[0m in \u001b[0;36mgrader_dc\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrader_dc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.929\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mU1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomized_svd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjacency_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Please don't change random state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg5XNbDWCIKI"
      },
      "source": [
        "<font color='red'>Compute MSE (mean squared error) for predicted ratings</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WUjNy0TDQX6"
      },
      "source": [
        "for each epoch, print the MSE value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2pCy1AKCafw"
      },
      "source": [
        "<pre>\n",
        "for each epoch:\n",
        "\n",
        "    for each pair of (user, movie):\n",
        "\n",
        "        b_i =  b_i - learning_rate * dL/db_i\n",
        "\n",
        "        c_j =  c_j - learning_rate * dL/dc_j\n",
        "\n",
        "predict the ratings with formula\n",
        "</pre>\n",
        "\n",
        "$\\hat{y}_{ij} = \\mu + b_i + c_j + \\text{dot_product}(u_i , v_j) $"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9hHhYSfJPVS"
      },
      "source": [
        "adj = adjacency_matrix.toarray()"
      ],
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiKj-M6d2a-Y"
      },
      "source": [
        "from tqdm import tqdm\n",
        "Y = []\n",
        "alpha = 0.01\n",
        "i = 50\n",
        "MSE = []\n",
        "learning_rate = 0.01\n",
        "mu=m_u(data['rating'])\n",
        "y_ = np.zeros((943,1681))\n",
        "b_i_new = b_i\n",
        "c_j_new = c_j\n",
        "mse = 0\n",
        "count  = 0\n",
        "while(i>0):\n",
        "  mse = 0\n",
        "  for j in range(len(users)):\n",
        "    for k in range(len(items)):\n",
        "      u = users[j]\n",
        "      m = items[k]\n",
        "      if adj[j][k] != 0:\n",
        "        db = derivative_db(u,m,adj[j][k],U,VT,mu,alpha,b_i[j],c_j[k]) # finding db \n",
        "        dc = derivative_dc(u,m,adj[j][k],U,VT,mu,alpha,b_i[j],c_j[k]) #finding dc\n",
        "        b_i_new[j] = b_i[j] - learning_rate*db\n",
        "        c_j_new[k] = c_j[k] - learning_rate*dc\n",
        "        y_[i][j] = b_i[j]+c_j[k]+mu+np.dot(U[users[j]],VT[:,items[k]])\n",
        "        b_i[j] = b_i_new[j]\n",
        "        c_j[k] = c_j_new[k]\n",
        "        mse+=(adj[j][k]-(b_i_new[j]+c_j_new[k]+mu+np.dot(U[users[j]],VT[:,items[k]])))**2 #finding mean squared error \n",
        "  MSE.append(mse/89992)\n",
        "  i-=1\n"
      ],
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRtoEm5gu1rO",
        "outputId": "d7e98310-c8ad-4f7d-ae73-60f87caefef6"
      },
      "source": [
        "MSE"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9498344969653528,\n",
              " 0.9008469577201043,\n",
              " 0.8921194628385596,\n",
              " 0.8884975370456183,\n",
              " 0.8865746098491997,\n",
              " 0.8854042095024072,\n",
              " 0.8846229699960352,\n",
              " 0.884065906667918,\n",
              " 0.8836488090083722,\n",
              " 0.8833247279512504,\n",
              " 0.8830655941570061,\n",
              " 0.882853644222159,\n",
              " 0.8826770959848079,\n",
              " 0.8825278219682089,\n",
              " 0.8824000277469866,\n",
              " 0.8822894652363465,\n",
              " 0.8821929450024265,\n",
              " 0.8821080230228298,\n",
              " 0.8820327931261032,\n",
              " 0.881965745620444,\n",
              " 0.881905668628241,\n",
              " 0.8818515777161359,\n",
              " 0.8818026647252092,\n",
              " 0.8817582599131273,\n",
              " 0.8817178035058312,\n",
              " 0.881680824019563,\n",
              " 0.8816469215320519,\n",
              " 0.8816157546248791,\n",
              " 0.8815870300856735,\n",
              " 0.8815604947094978,\n",
              " 0.881535928715931,\n",
              " 0.8815131404210277,\n",
              " 0.8814919618940983,\n",
              " 0.8814722453932639,\n",
              " 0.8814538604221718,\n",
              " 0.8814366912853565,\n",
              " 0.881420635046968,\n",
              " 0.8814055998175827,\n",
              " 0.8813915033094053,\n",
              " 0.8813782716124058,\n",
              " 0.881365838153029,\n",
              " 0.8813541428046836,\n",
              " 0.8813431311249714,\n",
              " 0.8813327536990094,\n",
              " 0.8813229655719547,\n",
              " 0.8813137257573905,\n",
              " 0.8813049968094545,\n",
              " 0.8812967444495341,\n",
              " 0.8812889372396809,\n",
              " 0.8812815462956763]"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTXYZFFUVSg5"
      },
      "source": [
        "<font color='red'>Plot epoch number vs MSE </font>\n",
        "\n",
        "* epoch number on X-axis\n",
        "* MSE on Y-axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmV0udWq8sjf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "igkkO3EvVRt6",
        "outputId": "28b98f36-6a55-4b12-fb1c-db4163059e1d"
      },
      "source": [
        "plt.plot(np.arange(1,51),MSE)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('MSE v/s epoches')"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'MSE v/s epoches')"
            ]
          },
          "metadata": {},
          "execution_count": 308
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeWAGkT6C9kq"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkIQOOo1C9o7"
      },
      "source": [
        "# <font color='red'> Task 2</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kl4Ryi_7E_T"
      },
      "source": [
        "- For this task you have to consider the user_matrix U and the user_info.csv file.\n",
        "- You have to consider is_male columns as  output features and rest as input features. Now you have to fit a model by posing this problem as binary classification task.\n",
        "- You can apply any model like Logistic regression or Decision tree and check the performance of the model. \n",
        "- Do plot confusion matrix after fitting your model and write your observations how your model is performing in this task.\n",
        "\n",
        "- Optional work- You can try scaling your U matrix.Scaling means changing the values of n_componenets while performing svd\n",
        "  and then check your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1FTc39gDdti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774f9407-a5ee-43bc-fad3-4d11c7b2336c"
      },
      "source": [
        "U"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.0662257 ,  0.00788853, -0.01253125, ...,  0.01367393,\n",
              "        -0.01599038,  0.07419343],\n",
              "       [ 0.01364432, -0.04889502,  0.05655371, ..., -0.01525794,\n",
              "         0.00837367, -0.01568815],\n",
              "       [ 0.00543826, -0.0251278 ,  0.02002774, ..., -0.02052443,\n",
              "         0.02072003, -0.02445033],\n",
              "       ...,\n",
              "       [ 0.00738924, -0.02597375,  0.0063433 , ...,  0.02178487,\n",
              "        -0.01543472,  0.00302407],\n",
              "       [ 0.02499924,  0.00447791,  0.02605644, ...,  0.03279804,\n",
              "        -0.02790097, -0.04015734],\n",
              "       [ 0.04337341, -0.00281487, -0.0607779 , ..., -0.02570051,\n",
              "        -0.0559467 ,  0.07182758]])"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7e_3BBsHpWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f9a2cd-12d2-4eae-c713-e6213abb9b2a"
      },
      "source": [
        "data1 = pd.read_csv('user_info.csv.txt')\n",
        "data1.shape"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(943, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3K5ZHmSHpWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1192325-845d-4017-dadb-37182004c0d7"
      },
      "source": [
        "target = data1['is_male']\n",
        "target"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      0\n",
              "2      1\n",
              "3      1\n",
              "4      0\n",
              "      ..\n",
              "938    0\n",
              "939    1\n",
              "940    1\n",
              "941    0\n",
              "942    1\n",
              "Name: is_male, Length: 943, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ikpA8DtxXdM"
      },
      "source": [
        "data1 = data1.drop(['is_male'],axis = 1)"
      ],
      "execution_count": 312,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SkF9cE9xsi_"
      },
      "source": [
        "data2 = pd.DataFrame(U)"
      ],
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDvMa8vex8l_",
        "outputId": "6c7ffc8c-85ef-4424-e65a-f931642cf1e2"
      },
      "source": [
        "data1.shape"
      ],
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(943, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5xVyxCZz3fO",
        "outputId": "99796cb6-0543-43a6-c2bb-5053b03a9c13"
      },
      "source": [
        "data2.shape"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(943, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO8p9abNz8W9"
      },
      "source": [
        "data = pd.concat([data1,data2],axis = 1)"
      ],
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "RIgdmgPa0cbV",
        "outputId": "9dfe60d3-5d03-4122-d09a-75623ea312de"
      },
      "source": [
        "data"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>age</th>\n",
              "      <th>orig_user_id</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>0.066226</td>\n",
              "      <td>0.007889</td>\n",
              "      <td>-0.012531</td>\n",
              "      <td>-0.086164</td>\n",
              "      <td>0.024869</td>\n",
              "      <td>0.006658</td>\n",
              "      <td>0.080034</td>\n",
              "      <td>-0.027573</td>\n",
              "      <td>0.067700</td>\n",
              "      <td>0.020585</td>\n",
              "      <td>-0.026589</td>\n",
              "      <td>0.025816</td>\n",
              "      <td>-0.037820</td>\n",
              "      <td>0.041183</td>\n",
              "      <td>-0.018008</td>\n",
              "      <td>0.001604</td>\n",
              "      <td>-0.081980</td>\n",
              "      <td>0.016199</td>\n",
              "      <td>-0.067551</td>\n",
              "      <td>-0.054105</td>\n",
              "      <td>-0.115878</td>\n",
              "      <td>-0.008513</td>\n",
              "      <td>0.042306</td>\n",
              "      <td>-0.055500</td>\n",
              "      <td>0.041284</td>\n",
              "      <td>0.065471</td>\n",
              "      <td>-0.084438</td>\n",
              "      <td>-0.031022</td>\n",
              "      <td>0.033728</td>\n",
              "      <td>-0.015362</td>\n",
              "      <td>-0.048623</td>\n",
              "      <td>-0.055976</td>\n",
              "      <td>0.046354</td>\n",
              "      <td>-0.140079</td>\n",
              "      <td>-0.038362</td>\n",
              "      <td>-0.057798</td>\n",
              "      <td>0.034722</td>\n",
              "      <td>0.006224</td>\n",
              "      <td>0.045228</td>\n",
              "      <td>-0.031320</td>\n",
              "      <td>-0.020654</td>\n",
              "      <td>-0.088956</td>\n",
              "      <td>-0.000420</td>\n",
              "      <td>0.040191</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.023866</td>\n",
              "      <td>0.057684</td>\n",
              "      <td>0.013674</td>\n",
              "      <td>-0.015990</td>\n",
              "      <td>0.074193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>2</td>\n",
              "      <td>0.013644</td>\n",
              "      <td>-0.048895</td>\n",
              "      <td>0.056554</td>\n",
              "      <td>0.015810</td>\n",
              "      <td>-0.012037</td>\n",
              "      <td>0.017731</td>\n",
              "      <td>0.010700</td>\n",
              "      <td>-0.010228</td>\n",
              "      <td>0.028445</td>\n",
              "      <td>-0.009501</td>\n",
              "      <td>0.059311</td>\n",
              "      <td>-0.031067</td>\n",
              "      <td>-0.011233</td>\n",
              "      <td>0.057291</td>\n",
              "      <td>0.005084</td>\n",
              "      <td>-0.027537</td>\n",
              "      <td>0.011444</td>\n",
              "      <td>-0.013841</td>\n",
              "      <td>0.005316</td>\n",
              "      <td>0.014117</td>\n",
              "      <td>0.011050</td>\n",
              "      <td>0.006107</td>\n",
              "      <td>-0.020931</td>\n",
              "      <td>0.005185</td>\n",
              "      <td>0.007162</td>\n",
              "      <td>-0.013748</td>\n",
              "      <td>-0.051372</td>\n",
              "      <td>0.019939</td>\n",
              "      <td>0.012433</td>\n",
              "      <td>-0.041727</td>\n",
              "      <td>0.029559</td>\n",
              "      <td>-0.025662</td>\n",
              "      <td>0.031042</td>\n",
              "      <td>-0.008309</td>\n",
              "      <td>-0.007463</td>\n",
              "      <td>-0.009311</td>\n",
              "      <td>-0.014304</td>\n",
              "      <td>0.006761</td>\n",
              "      <td>0.040882</td>\n",
              "      <td>-0.016365</td>\n",
              "      <td>-0.035406</td>\n",
              "      <td>0.016057</td>\n",
              "      <td>-0.015096</td>\n",
              "      <td>0.006371</td>\n",
              "      <td>-0.025115</td>\n",
              "      <td>-0.016435</td>\n",
              "      <td>-0.025939</td>\n",
              "      <td>-0.015258</td>\n",
              "      <td>0.008374</td>\n",
              "      <td>-0.015688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>0.005438</td>\n",
              "      <td>-0.025128</td>\n",
              "      <td>0.020028</td>\n",
              "      <td>0.032832</td>\n",
              "      <td>0.035080</td>\n",
              "      <td>0.001921</td>\n",
              "      <td>0.007691</td>\n",
              "      <td>-0.000993</td>\n",
              "      <td>-0.021173</td>\n",
              "      <td>-0.003267</td>\n",
              "      <td>0.001032</td>\n",
              "      <td>0.010390</td>\n",
              "      <td>0.001272</td>\n",
              "      <td>-0.020658</td>\n",
              "      <td>0.001799</td>\n",
              "      <td>0.011665</td>\n",
              "      <td>-0.012615</td>\n",
              "      <td>0.010786</td>\n",
              "      <td>-0.018960</td>\n",
              "      <td>0.003112</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.006290</td>\n",
              "      <td>0.026231</td>\n",
              "      <td>0.020256</td>\n",
              "      <td>0.026590</td>\n",
              "      <td>0.009998</td>\n",
              "      <td>0.011378</td>\n",
              "      <td>0.009667</td>\n",
              "      <td>-0.004611</td>\n",
              "      <td>0.022092</td>\n",
              "      <td>-0.034410</td>\n",
              "      <td>-0.012368</td>\n",
              "      <td>-0.008825</td>\n",
              "      <td>-0.005306</td>\n",
              "      <td>0.021949</td>\n",
              "      <td>0.012490</td>\n",
              "      <td>-0.002539</td>\n",
              "      <td>0.007437</td>\n",
              "      <td>-0.032436</td>\n",
              "      <td>-0.010996</td>\n",
              "      <td>0.021206</td>\n",
              "      <td>-0.001817</td>\n",
              "      <td>-0.011599</td>\n",
              "      <td>0.014114</td>\n",
              "      <td>0.013303</td>\n",
              "      <td>0.002705</td>\n",
              "      <td>-0.019007</td>\n",
              "      <td>-0.020524</td>\n",
              "      <td>0.020720</td>\n",
              "      <td>-0.024450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>0.005704</td>\n",
              "      <td>-0.018211</td>\n",
              "      <td>0.010898</td>\n",
              "      <td>0.021867</td>\n",
              "      <td>0.013920</td>\n",
              "      <td>-0.014181</td>\n",
              "      <td>0.012242</td>\n",
              "      <td>-0.009123</td>\n",
              "      <td>-0.012769</td>\n",
              "      <td>0.006051</td>\n",
              "      <td>-0.000232</td>\n",
              "      <td>-0.013539</td>\n",
              "      <td>-0.001744</td>\n",
              "      <td>-0.038318</td>\n",
              "      <td>0.000388</td>\n",
              "      <td>0.009385</td>\n",
              "      <td>-0.016336</td>\n",
              "      <td>0.021989</td>\n",
              "      <td>0.003952</td>\n",
              "      <td>-0.015766</td>\n",
              "      <td>0.007497</td>\n",
              "      <td>-0.001556</td>\n",
              "      <td>-0.001908</td>\n",
              "      <td>0.004402</td>\n",
              "      <td>-0.002034</td>\n",
              "      <td>0.014429</td>\n",
              "      <td>-0.014767</td>\n",
              "      <td>-0.009327</td>\n",
              "      <td>-0.009356</td>\n",
              "      <td>-0.003314</td>\n",
              "      <td>-0.019292</td>\n",
              "      <td>-0.026677</td>\n",
              "      <td>0.006082</td>\n",
              "      <td>0.023002</td>\n",
              "      <td>-0.007211</td>\n",
              "      <td>0.012545</td>\n",
              "      <td>0.019108</td>\n",
              "      <td>-0.017378</td>\n",
              "      <td>0.015834</td>\n",
              "      <td>-0.012839</td>\n",
              "      <td>-0.003531</td>\n",
              "      <td>0.028445</td>\n",
              "      <td>-0.002435</td>\n",
              "      <td>0.001153</td>\n",
              "      <td>-0.006252</td>\n",
              "      <td>-0.013871</td>\n",
              "      <td>-0.005234</td>\n",
              "      <td>-0.009855</td>\n",
              "      <td>0.011153</td>\n",
              "      <td>0.001654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>0.034122</td>\n",
              "      <td>0.009005</td>\n",
              "      <td>-0.044054</td>\n",
              "      <td>-0.016049</td>\n",
              "      <td>0.004326</td>\n",
              "      <td>-0.021503</td>\n",
              "      <td>0.095574</td>\n",
              "      <td>0.079511</td>\n",
              "      <td>-0.017195</td>\n",
              "      <td>0.029423</td>\n",
              "      <td>0.018167</td>\n",
              "      <td>-0.046288</td>\n",
              "      <td>0.005283</td>\n",
              "      <td>0.045446</td>\n",
              "      <td>0.000740</td>\n",
              "      <td>-0.002116</td>\n",
              "      <td>0.012727</td>\n",
              "      <td>0.021502</td>\n",
              "      <td>0.044736</td>\n",
              "      <td>0.014463</td>\n",
              "      <td>-0.036230</td>\n",
              "      <td>0.003443</td>\n",
              "      <td>0.022960</td>\n",
              "      <td>0.038229</td>\n",
              "      <td>-0.002015</td>\n",
              "      <td>0.088679</td>\n",
              "      <td>0.018127</td>\n",
              "      <td>0.051700</td>\n",
              "      <td>-0.007506</td>\n",
              "      <td>-0.006008</td>\n",
              "      <td>0.028369</td>\n",
              "      <td>0.045241</td>\n",
              "      <td>-0.054008</td>\n",
              "      <td>0.032551</td>\n",
              "      <td>-0.042171</td>\n",
              "      <td>-0.039276</td>\n",
              "      <td>-0.052612</td>\n",
              "      <td>-0.057560</td>\n",
              "      <td>-0.002572</td>\n",
              "      <td>0.001459</td>\n",
              "      <td>-0.033754</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>-0.024007</td>\n",
              "      <td>0.013411</td>\n",
              "      <td>-0.012693</td>\n",
              "      <td>0.037560</td>\n",
              "      <td>0.008717</td>\n",
              "      <td>-0.025792</td>\n",
              "      <td>0.007797</td>\n",
              "      <td>-0.024701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>938</td>\n",
              "      <td>26</td>\n",
              "      <td>939</td>\n",
              "      <td>0.010350</td>\n",
              "      <td>-0.038006</td>\n",
              "      <td>0.006501</td>\n",
              "      <td>-0.013989</td>\n",
              "      <td>-0.051223</td>\n",
              "      <td>-0.001718</td>\n",
              "      <td>-0.037136</td>\n",
              "      <td>0.010857</td>\n",
              "      <td>0.010762</td>\n",
              "      <td>0.001967</td>\n",
              "      <td>-0.015176</td>\n",
              "      <td>-0.015817</td>\n",
              "      <td>-0.013877</td>\n",
              "      <td>0.013323</td>\n",
              "      <td>-0.008859</td>\n",
              "      <td>0.025075</td>\n",
              "      <td>-0.010123</td>\n",
              "      <td>-0.000591</td>\n",
              "      <td>0.045561</td>\n",
              "      <td>0.000425</td>\n",
              "      <td>-0.001344</td>\n",
              "      <td>0.013066</td>\n",
              "      <td>-0.060134</td>\n",
              "      <td>-0.008968</td>\n",
              "      <td>0.018151</td>\n",
              "      <td>-0.037780</td>\n",
              "      <td>-0.022289</td>\n",
              "      <td>0.008101</td>\n",
              "      <td>-0.011181</td>\n",
              "      <td>-0.002721</td>\n",
              "      <td>0.028180</td>\n",
              "      <td>-0.035508</td>\n",
              "      <td>-0.016911</td>\n",
              "      <td>0.028448</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>-0.001154</td>\n",
              "      <td>0.028248</td>\n",
              "      <td>0.002852</td>\n",
              "      <td>-0.018167</td>\n",
              "      <td>-0.015967</td>\n",
              "      <td>-0.010007</td>\n",
              "      <td>0.014666</td>\n",
              "      <td>-0.046707</td>\n",
              "      <td>0.025769</td>\n",
              "      <td>-0.033437</td>\n",
              "      <td>0.002861</td>\n",
              "      <td>-0.019907</td>\n",
              "      <td>-0.017454</td>\n",
              "      <td>0.042117</td>\n",
              "      <td>0.042634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>939</td>\n",
              "      <td>32</td>\n",
              "      <td>940</td>\n",
              "      <td>0.031624</td>\n",
              "      <td>-0.007730</td>\n",
              "      <td>0.032983</td>\n",
              "      <td>0.013862</td>\n",
              "      <td>0.023619</td>\n",
              "      <td>-0.008443</td>\n",
              "      <td>0.054688</td>\n",
              "      <td>-0.031091</td>\n",
              "      <td>-0.015142</td>\n",
              "      <td>-0.000058</td>\n",
              "      <td>-0.006561</td>\n",
              "      <td>-0.034766</td>\n",
              "      <td>0.050463</td>\n",
              "      <td>0.053561</td>\n",
              "      <td>-0.037202</td>\n",
              "      <td>-0.011454</td>\n",
              "      <td>0.052498</td>\n",
              "      <td>-0.039544</td>\n",
              "      <td>0.034681</td>\n",
              "      <td>0.000644</td>\n",
              "      <td>-0.001244</td>\n",
              "      <td>0.054052</td>\n",
              "      <td>-0.047252</td>\n",
              "      <td>-0.045893</td>\n",
              "      <td>-0.045874</td>\n",
              "      <td>-0.043492</td>\n",
              "      <td>-0.010495</td>\n",
              "      <td>-0.038447</td>\n",
              "      <td>-0.067590</td>\n",
              "      <td>0.046701</td>\n",
              "      <td>0.005532</td>\n",
              "      <td>-0.016858</td>\n",
              "      <td>-0.016276</td>\n",
              "      <td>0.032353</td>\n",
              "      <td>0.017114</td>\n",
              "      <td>-0.023551</td>\n",
              "      <td>-0.011352</td>\n",
              "      <td>-0.018965</td>\n",
              "      <td>0.008377</td>\n",
              "      <td>0.015266</td>\n",
              "      <td>-0.036458</td>\n",
              "      <td>0.020590</td>\n",
              "      <td>0.006715</td>\n",
              "      <td>-0.063094</td>\n",
              "      <td>0.015122</td>\n",
              "      <td>0.027750</td>\n",
              "      <td>-0.014044</td>\n",
              "      <td>0.033902</td>\n",
              "      <td>-0.020887</td>\n",
              "      <td>-0.002485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>940</td>\n",
              "      <td>20</td>\n",
              "      <td>941</td>\n",
              "      <td>0.007389</td>\n",
              "      <td>-0.025974</td>\n",
              "      <td>0.006343</td>\n",
              "      <td>-0.017067</td>\n",
              "      <td>-0.007397</td>\n",
              "      <td>-0.020780</td>\n",
              "      <td>0.015469</td>\n",
              "      <td>0.015052</td>\n",
              "      <td>0.000977</td>\n",
              "      <td>-0.004602</td>\n",
              "      <td>-0.007945</td>\n",
              "      <td>0.007990</td>\n",
              "      <td>-0.002959</td>\n",
              "      <td>-0.018620</td>\n",
              "      <td>-0.005114</td>\n",
              "      <td>-0.020684</td>\n",
              "      <td>0.003580</td>\n",
              "      <td>0.047429</td>\n",
              "      <td>0.026034</td>\n",
              "      <td>-0.020872</td>\n",
              "      <td>0.015492</td>\n",
              "      <td>-0.009363</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>-0.007505</td>\n",
              "      <td>-0.006534</td>\n",
              "      <td>0.002333</td>\n",
              "      <td>0.006665</td>\n",
              "      <td>0.002713</td>\n",
              "      <td>0.012425</td>\n",
              "      <td>-0.015437</td>\n",
              "      <td>-0.017555</td>\n",
              "      <td>-0.012535</td>\n",
              "      <td>-0.021683</td>\n",
              "      <td>0.038439</td>\n",
              "      <td>-0.007763</td>\n",
              "      <td>0.018384</td>\n",
              "      <td>0.033914</td>\n",
              "      <td>0.023285</td>\n",
              "      <td>0.022858</td>\n",
              "      <td>0.004349</td>\n",
              "      <td>0.017461</td>\n",
              "      <td>0.026797</td>\n",
              "      <td>0.007049</td>\n",
              "      <td>-0.019528</td>\n",
              "      <td>-0.005771</td>\n",
              "      <td>0.010121</td>\n",
              "      <td>0.019443</td>\n",
              "      <td>0.021785</td>\n",
              "      <td>-0.015435</td>\n",
              "      <td>0.003024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>941</td>\n",
              "      <td>48</td>\n",
              "      <td>942</td>\n",
              "      <td>0.024999</td>\n",
              "      <td>0.004478</td>\n",
              "      <td>0.026056</td>\n",
              "      <td>0.077343</td>\n",
              "      <td>-0.000767</td>\n",
              "      <td>-0.038300</td>\n",
              "      <td>-0.010409</td>\n",
              "      <td>-0.016338</td>\n",
              "      <td>-0.011159</td>\n",
              "      <td>-0.031684</td>\n",
              "      <td>-0.007343</td>\n",
              "      <td>0.043051</td>\n",
              "      <td>0.029343</td>\n",
              "      <td>0.027102</td>\n",
              "      <td>0.033207</td>\n",
              "      <td>0.017576</td>\n",
              "      <td>0.005697</td>\n",
              "      <td>0.021942</td>\n",
              "      <td>0.015963</td>\n",
              "      <td>0.005011</td>\n",
              "      <td>-0.033921</td>\n",
              "      <td>-0.011317</td>\n",
              "      <td>0.009642</td>\n",
              "      <td>-0.023783</td>\n",
              "      <td>-0.032425</td>\n",
              "      <td>0.039636</td>\n",
              "      <td>0.014829</td>\n",
              "      <td>0.049413</td>\n",
              "      <td>-0.023043</td>\n",
              "      <td>0.022499</td>\n",
              "      <td>0.049767</td>\n",
              "      <td>0.003436</td>\n",
              "      <td>-0.027128</td>\n",
              "      <td>0.017792</td>\n",
              "      <td>-0.018501</td>\n",
              "      <td>0.003473</td>\n",
              "      <td>0.011895</td>\n",
              "      <td>-0.041302</td>\n",
              "      <td>-0.073853</td>\n",
              "      <td>0.003894</td>\n",
              "      <td>-0.047437</td>\n",
              "      <td>-0.023650</td>\n",
              "      <td>0.083642</td>\n",
              "      <td>-0.027709</td>\n",
              "      <td>-0.043656</td>\n",
              "      <td>-0.067282</td>\n",
              "      <td>0.077231</td>\n",
              "      <td>0.032798</td>\n",
              "      <td>-0.027901</td>\n",
              "      <td>-0.040157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>942</td>\n",
              "      <td>22</td>\n",
              "      <td>943</td>\n",
              "      <td>0.043373</td>\n",
              "      <td>-0.002815</td>\n",
              "      <td>-0.060778</td>\n",
              "      <td>-0.031584</td>\n",
              "      <td>0.039834</td>\n",
              "      <td>0.006366</td>\n",
              "      <td>-0.040937</td>\n",
              "      <td>-0.069160</td>\n",
              "      <td>0.005817</td>\n",
              "      <td>-0.044323</td>\n",
              "      <td>0.079889</td>\n",
              "      <td>-0.022653</td>\n",
              "      <td>0.003727</td>\n",
              "      <td>-0.056243</td>\n",
              "      <td>0.036345</td>\n",
              "      <td>-0.036075</td>\n",
              "      <td>0.007742</td>\n",
              "      <td>-0.019197</td>\n",
              "      <td>0.006625</td>\n",
              "      <td>0.040268</td>\n",
              "      <td>-0.052161</td>\n",
              "      <td>0.000079</td>\n",
              "      <td>0.012275</td>\n",
              "      <td>-0.043518</td>\n",
              "      <td>-0.084423</td>\n",
              "      <td>0.038237</td>\n",
              "      <td>-0.001970</td>\n",
              "      <td>0.036600</td>\n",
              "      <td>0.031721</td>\n",
              "      <td>-0.003184</td>\n",
              "      <td>0.061104</td>\n",
              "      <td>0.008988</td>\n",
              "      <td>-0.026394</td>\n",
              "      <td>-0.041983</td>\n",
              "      <td>0.021759</td>\n",
              "      <td>0.029240</td>\n",
              "      <td>-0.024470</td>\n",
              "      <td>-0.021899</td>\n",
              "      <td>0.014605</td>\n",
              "      <td>0.051855</td>\n",
              "      <td>-0.018997</td>\n",
              "      <td>0.043034</td>\n",
              "      <td>-0.011786</td>\n",
              "      <td>0.035559</td>\n",
              "      <td>-0.026861</td>\n",
              "      <td>0.028881</td>\n",
              "      <td>-0.048556</td>\n",
              "      <td>-0.025701</td>\n",
              "      <td>-0.055947</td>\n",
              "      <td>0.071828</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 53 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     user_id  age  orig_user_id  ...        47        48        49\n",
              "0          0   24             1  ...  0.013674 -0.015990  0.074193\n",
              "1          1   53             2  ... -0.015258  0.008374 -0.015688\n",
              "2          2   23             3  ... -0.020524  0.020720 -0.024450\n",
              "3          3   24             4  ... -0.009855  0.011153  0.001654\n",
              "4          4   33             5  ... -0.025792  0.007797 -0.024701\n",
              "..       ...  ...           ...  ...       ...       ...       ...\n",
              "938      938   26           939  ... -0.017454  0.042117  0.042634\n",
              "939      939   32           940  ...  0.033902 -0.020887 -0.002485\n",
              "940      940   20           941  ...  0.021785 -0.015435  0.003024\n",
              "941      941   48           942  ...  0.032798 -0.027901 -0.040157\n",
              "942      942   22           943  ... -0.025701 -0.055947  0.071828\n",
              "\n",
              "[943 rows x 53 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZqS_m0E0dcF",
        "outputId": "5155f63b-42d4-4b09-992d-e6d07c774729"
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user_id         0\n",
              "age             0\n",
              "orig_user_id    0\n",
              "0               0\n",
              "1               0\n",
              "2               0\n",
              "3               0\n",
              "4               0\n",
              "5               0\n",
              "6               0\n",
              "7               0\n",
              "8               0\n",
              "9               0\n",
              "10              0\n",
              "11              0\n",
              "12              0\n",
              "13              0\n",
              "14              0\n",
              "15              0\n",
              "16              0\n",
              "17              0\n",
              "18              0\n",
              "19              0\n",
              "20              0\n",
              "21              0\n",
              "22              0\n",
              "23              0\n",
              "24              0\n",
              "25              0\n",
              "26              0\n",
              "27              0\n",
              "28              0\n",
              "29              0\n",
              "30              0\n",
              "31              0\n",
              "32              0\n",
              "33              0\n",
              "34              0\n",
              "35              0\n",
              "36              0\n",
              "37              0\n",
              "38              0\n",
              "39              0\n",
              "40              0\n",
              "41              0\n",
              "42              0\n",
              "43              0\n",
              "44              0\n",
              "45              0\n",
              "46              0\n",
              "47              0\n",
              "48              0\n",
              "49              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvNaZIyW5CIJ",
        "outputId": "d49d9319-337a-4f86-eb65-66f4ca0848fc"
      },
      "source": [
        "data.duplicated().sum()"
      ],
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlnUCWthF4M6",
        "outputId": "66d03d39-ec2f-4ff9-f965-ad7379a06974"
      },
      "source": [
        "target.value_counts()"
      ],
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    670\n",
              "0    273\n",
              "Name: is_male, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMM-GJ8J6OHC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train , X_test ,y_train, y_test = train_test_split(data,target,test_size = 0.33,random_state = 10)"
      ],
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsee-061C5Hu",
        "outputId": "5af51cb7-69cb-40d6-d245-a73ce0ade23d"
      },
      "source": [
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(631, 53) (631,)\n",
            "(312, 53) (312,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlCO3hx5C7os"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 325,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPtun6koDfFR"
      },
      "source": [
        "Logistic = LogisticRegression(random_state = 10)\n",
        "param = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}] \n",
        "model = RandomizedSearchCV(Logistic,param,random_state = 10)"
      ],
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsQX2FhDE2LD",
        "outputId": "accd04a0-6126-4242-a70d-06ffa0c71182"
      },
      "source": [
        "model.fit(X_train,y_train)"
      ],
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(estimator=LogisticRegression(random_state=10),\n",
              "                   param_distributions=[{'C': [0.0001, 0.01, 1, 100, 10000]}],\n",
              "                   random_state=10)"
            ]
          },
          "metadata": {},
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv0Ir3fVGQr8",
        "outputId": "c22f06c7-a409-4707-8cd9-36cec5357167"
      },
      "source": [
        "model.best_estimator_"
      ],
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10000, random_state=10)"
            ]
          },
          "metadata": {},
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYpPcbEcGqZi"
      },
      "source": [
        "model1 = LogisticRegression(C = 10000,random_state=10)"
      ],
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo4msdZUG8Fe",
        "outputId": "aebf9183-e15e-42a3-c960-9b2fae971b19"
      },
      "source": [
        " model1.fit(X_train,y_train)"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10000, random_state=10)"
            ]
          },
          "metadata": {},
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcvp7QDtHBnj"
      },
      "source": [
        "y_pred = model1.predict(X_test)"
      ],
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "hVM37MvVOrKC",
        "outputId": "1619157f-f7ea-4b44-c1da-6f00dbf6f857"
      },
      "source": [
        "plot_confusion_matrix(model1,X_test,y_test)\n",
        "plt.show()\n",
        "\n",
        "roc_auc_score(y_test, model1.predict_proba(X_test)[:, 1])"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7430541263634493"
            ]
          },
          "metadata": {},
          "execution_count": 333
        }
      ]
    }
  ]
}